---
title: "Group 9 Presentation"
subtitle: "Heart Disease Classification"
author: "Henrique Magalhaes Rio , Oriana Meldrum, Jorie Alvis"
date: "12/8/2021"
output:
  slidy_presentation: default
  ioslides_presentation: default
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(repos='http://cran.rstudio.org')
have.packages <- installed.packages()
cran.packages <- c('devtools','plotrix','randomForest','tree')
to.install <- setdiff(cran.packages, have.packages[,1])
if(length(to.install)>0) install.packages(to.install)

library(devtools)
if(!('reprtree' %in% installed.packages())){
  install_github('araastat/reprtree')
}
for(p in c(cran.packages, 'reprtree')) eval(substitute(library(pkg), list(pkg=p)))
```

```{r, include=FALSE}


#reproducibility
set.seed(445)

library(ISLR)
library(leaps)
library(tidyr)
library(dplyr)
library(ggplot2)
library(glmnet)
library(caret)
library(pls) 
library(tree)
library(randomForest)
library(knitr)
library(class)
library(fastDummies)
library(reprtree)
library(MASS)
library(e1071)
library(gbm)








train <- read.csv("train.csv")
test <- read.csv("test.csv")


train$ChestPainType <- as.factor(train$ChestPainType)
train$Sex <- as.factor(train$Sex)
train$FastingBS <- as.factor(train$FastingBS)
train$RestingECG <- as.factor(train$RestingECG)
train$ExerciseAngina <- as.factor(train$ExerciseAngina)
train$ST_Slope <- as.factor(train$ST_Slope)
train$HeartDisease <- as.factor(train$HeartDisease)


test$ChestPainType <- as.factor(test$ChestPainType)
test$Sex <- as.factor(test$Sex)
test$FastingBS <- as.factor(test$FastingBS)
test$RestingECG <- as.factor(test$RestingECG)
test$ExerciseAngina <- as.factor(test$ExerciseAngina)
test$ST_Slope <- as.factor(test$ST_Slope)
test$HeartDisease <- as.factor(test$HeartDisease)

```



## Introduction

In 2019 659,041 Americans died of heart disease. Four out of five heart disease deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age. Heart failure is a common event caused by heart disease and this dataset we used contains 11 variables that can be used to predict a possible heart disease.

People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors) need early detection and management so machine learning techniques are of great clinical intrest for early detection. 

(https://www.cdc.gov/nchs/fastats/leading-causes-of-death.htm, https://www.kaggle.com/fedesoriano/heart-failure-prediction)


## Data {.smaller}

- There are 918 observations which we split into 60/40 for training and validation.

- 12 predictors are included in the data which are:

+ Age

+ Sex M/F

+ Chest Pain Type:

++ TA: Typical Angina

++ ATA: Atypical Angina

++ NAP: Non-Anginal Pain

++ ASY: Asymptomatic

+ Resting Blood Pressure [mm Hg]

+ Cholesterol [mm/dl]

+ Fasting Blood Sugar Y/N

## Data {.smaller}

+ Resting Electrocardiogram


++ Normal: Normal

++ ST: Having ST-T Wave abnormality

++ LVH: Showing probable or definite left ventricular hypertrophy.

+ Max HR: Maximum heart rate achieved.

+ Exercise Angina: exercise-induced angine Y/N

+ Old peak: Oldpeak= ST value of depression

+ ST_Slope during exercise: 

++ Up sloping(up)

++ Flat(flat)

++ Down sloping (down)

+ Heart Disease: [1:Heart Disease, 0: Normal]
 
## Logistic Regression




```{r}
model_glm = glm(HeartDisease ~ ., data = train, family = "binomial")
summary(model_glm)


predicted2 <- predict(model_glm, newdata = test, "response")
predicted2 <- ifelse(predicted2>0.5,1,0)
confm2<-table(predicted=predicted2,True=test$HeartDisease)
kable(confm2)

paste("The overall fraction of correct predictions in the test dataset is :",(confm2[1,1]+confm2[2,2])/sum(confm2))

overall_logit <- (confm2[1,1]+confm2[2,2])/sum(confm2)

```


## LDA


```{r LDA}
LDA_model = lda(HeartDisease~., data=train)

preds = predict(LDA_model, test)

acc = sum(ifelse(preds$class == test$HeartDisease, 1, 0))/nrow(test)

table("Preds"=preds$class, "True"=test$HeartDisease)

overall_LDA <- acc
overall_LDA

LDA_model
```
## KNN

```{r message=FALSE, warning=FALSE,echo=FALSE}

temp_train <- dummy_cols(train, select_columns = c("Sex", "ChestPainType", "RestingECG", "ST_Slope", "ExerciseAngina") )
temp_test <- dummy_cols(test, select_columns = c("Sex", "ChestPainType", "RestingECG", "ST_Slope", "ExerciseAngina"))

drops <- c("Sex", "ChestPainType", "RestingECG", "ST_Slope", "ExerciseAngina")
temp_train <- temp_train[, !(names(temp_train) %in% drops)]
temp_test <-temp_test[, !(names(temp_test) %in% drops)]


#trainknn <- temp_train[-temp_train$HeartDisease]
#testknn <- test[-test$HeartDisease]


num_k <- seq(1:100)

my_cv <- knn.cv(temp_train, temp_train$HeartDisease, k=num_k)


knn_pred_1 <- knn(temp_train, temp_test, temp_train$HeartDisease, k=11)

confm_knn_1<-table(knn_pred_1,test$HeartDisease)

overall_knn_1 <- (confm_knn_1[1,1]+confm_knn_1[2,2])/sum(confm_knn_1)


overall_knn_1

 #confusion matrix
kable(confm_knn_1)
mean(knn_pred_1 !=test$HeartDisease)
```

## LASSO


```{r message=FALSE, warning=FALSE}

train_matrix <- model.matrix(HeartDisease ~ ., data = train)
test_matrix <- model.matrix(HeartDisease ~ ., data = test)
grid <- 10^seq(10, -2, length=100)

lasso <- glmnet(train_matrix, train$HeartDisease, alpha = 1, lambda = grid, thresh = 1e-12, family = "binomial")
#plot(lasso)



cv_lasso  <- cv.glmnet(train_matrix, train[, "HeartDisease"], alpha=1,family = "binomial")
#plot(cv_lasso)
best_lambda_lasso <- cv_lasso$lambda.min

lasso_prediction <- predict(lasso, newx = test_matrix, s = best_lambda_lasso)
lasso_MSE <- mean((lasso_prediction - test[, "HeartDisease"])^2)

num_zeros <-cv_lasso$nzero[which.min(cv_lasso$cvm)]


# MSE values to use:
paste("Tuning Lambda",best_lambda_lasso)
#lasso_MSE
paste("Number of zeros",num_zeros)



#Confusion Matrix
predicted_lasso <- predict(lasso, newx= test_matrix, s=best_lambda_lasso)
predicted_lasso <- ifelse(predicted_lasso>0.5,1,0)
confm_lasso<-table(predicted=predicted_lasso,True=test$HeartDisease)
confm_lasso


#Over all correct:
overall_lasso <- (confm_lasso[1,1]+confm_lasso[2,2])/sum(confm_lasso)

kable(confm_lasso) #confusion matrix
overall_lasso #over all correct
```


## Bagging
```{r,echo=FALSE,warning=FALSE,fig.width=6,fig.height=3}
train <- read.csv("train.csv")
test <- read.csv("test.csv")


train$ChestPainType <- as.factor(train$ChestPainType)
train$Sex <- as.factor(train$Sex)
train$FastingBS <- as.factor(train$FastingBS)
train$RestingECG <- as.factor(train$RestingECG)
train$ExerciseAngina <- as.factor(train$ExerciseAngina)
train$ST_Slope <- as.factor(train$ST_Slope)


test$ChestPainType <- as.factor(test$ChestPainType)
test$Sex <- as.factor(test$Sex)
test$FastingBS <- as.factor(test$FastingBS)
test$RestingECG <- as.factor(test$RestingECG)
test$ExerciseAngina <- as.factor(test$ExerciseAngina)
test$ST_Slope <- as.factor(test$ST_Slope)


bagging <- randomForest(HeartDisease ~ .,data = train, mtry = 19, ntree = 500, type = "class", 
                        importance = TRUE,
                        proximity = TRUE) 




#Confusion Matrix
predict_bag <- predict(bagging, newdata = test)
predicted_bag <- ifelse(predict_bag>0.5,1,0)
confm_bag<-table(predicted_bag,test$HeartDisease)


#MSE
bagging_mse <- mean((predict_bag - test$HeartDisease)^2) 

#Over all correct:
overall_bag <- (confm_bag[1,1]+confm_bag[2,2])/sum(confm_bag)

kable(confm_bag) #confusion matrix
overall_bag #over all correct


#Visulizaton of bagging
VI <- data.frame(var=names(test[,-12]), imp=varImp(bagging))

#sort variable importance descending
#VI_plot <- VI[order(VI$imp.0, decreasing=TRUE),]

#visualize variable importance with horizontal bar plot
#barplot(VI_plot$imp.0,
   #     names.arg=rownames(VI_plot),
    #    horiz=TRUE,
     #   col='steelblue',
      #  xlab='Variable Importance')


ggplot(VI)+geom_col(aes(x=var,y=Overall,fill=var))+coord_flip()+guides(fill=FALSE)+
  labs(x="Variable Name",y="Importance")
```


## Random Forest



```{r}
rf_fit <- randomForest(as.factor(HeartDisease) ~ ., data = train, mtry = sqrt(ncol(train)-1), importance = TRUE, type= "classification")

true <- test$HeartDisease
rf <- predict(rf_fit,test,type="class")



confm2<-table(predicted=rf,True=true)
confm2


paste("the overall fraction of correct predictions in the test dataset is :",(confm2[1,1]+confm2[2,2])/sum(confm2))


overall_RF <- (confm2[1,1]+confm2[2,2])/sum(confm2)
rf_fit

imp<-data.frame(rf_fit$importance)

imp$variables <- rownames(imp)
rownames(imp) <- 1:nrow(imp)

imp <- imp[order(imp$MeanDecreaseAccuracy),]

```

## Random Forest Plot


```{r}
ggplot(imp)+geom_col(aes(x=variables,y=MeanDecreaseAccuracy,fill=variables))+coord_flip()+labs(title="Variable Importance",y=" Mean decrease in Accuracy", x= " Variable")+scale_y_continuous(labels = scales::percent_format())+guides(fill="none")
```



## Representative Tree
- Following the paper "Identifying representative Trees From Ensembles"  by  Banerjee, et al.(2011) and the package reprtree we can get a representative tree from the random forest.

- This tree is calculated using a measure of similarity, in which 2 trees are similar if they have the same prediction for all observations.

- The representative tree is then choosen based on its averaged similarity between all other trees.

- Using this idea on the random forest we get the following tree:



## Representative Tree Plot
```{r fig.height=7, fig.width=15, message=FALSE, warning=FALSE,echo=FALSE}
reptree <- ReprTree(rf_fit, train, metric='d2')

plot(reptree, index=1)

```


## Boosting

```{r}

train <- read.csv("train.csv")
test <- read.csv("test.csv")


train$ChestPainType <- as.factor(train$ChestPainType)
train$Sex <- as.factor(train$Sex)
train$FastingBS <- as.factor(train$FastingBS)
train$RestingECG <- as.factor(train$RestingECG)
train$ExerciseAngina <- as.factor(train$ExerciseAngina)
train$ST_Slope <- as.factor(train$ST_Slope)


test$ChestPainType <- as.factor(test$ChestPainType)
test$Sex <- as.factor(test$Sex)
test$FastingBS <- as.factor(test$FastingBS)
test$RestingECG <- as.factor(test$RestingECG)
test$ExerciseAngina <- as.factor(test$ExerciseAngina)
test$ST_Slope <- as.factor(test$ST_Slope)



set.seed(445)




oob = trainControl(method = "oob")
cv_5 = trainControl(method = "cv", number = 5)

gbm_grid =  expand.grid(interaction.depth = 1:5,
                        n.trees = (1:5) * 200,
                        shrinkage = c(0.01,0.015,0.1),
                        n.minobsinnode = 10)


gbm_tune = train(as.factor(HeartDisease) ~ ., data = train,
                      method = "gbm",
                      trControl = cv_5,
                      verbose = FALSE,
                      tuneGrid = gbm_grid)


plot(gbm_tune)

```


- Tuning Parameters: n= 600 trees, shrinkage=0.01, interaction= 2.

```{r}
boost <- gbm(HeartDisease~.,data=train,n.trees=600,shrinkage=0.01,interaction.depth = 2 ,distribution = "bernoulli")


boostpred = ifelse(predict(boost,test, n.trees = 500, "response") > 0.5, "1", "0")

confboost<-table(predicted = boostpred, actual = test$HeartDisease)
confboost
error<-(confboost[1,1]+confboost[2,2])/sum(confboost)
overall_boost <- error
overall_boost
```



```{r,include=FALSE}
summa<-summary(boost)
```




```{r}
ggplot(summa)+geom_col(aes(x=var,y=rel.inf,fill=var))+coord_flip()+labs(y="Relative Influence", x= " Variable")+guides(fill="none")
```



## SVM


```{r SVM}

train <- read.csv("train.csv")
test <- read.csv("test.csv")


train$ChestPainType <- as.factor(train$ChestPainType)
train$Sex <- as.factor(train$Sex)
train$FastingBS <- as.factor(train$FastingBS)
train$RestingECG <- as.factor(train$RestingECG)
train$ExerciseAngina <- as.factor(train$ExerciseAngina)
train$ST_Slope <- as.factor(train$ST_Slope)


test$ChestPainType <- as.factor(test$ChestPainType)
test$Sex <- as.factor(test$Sex)
test$FastingBS <- as.factor(test$FastingBS)
test$RestingECG <- as.factor(test$RestingECG)
test$ExerciseAngina <- as.factor(test$ExerciseAngina)
test$ST_Slope <- as.factor(test$ST_Slope)


SVM_radial = svm(HeartDisease~., data=train, kernel="radial", gamma=0.25, cost=0.4)

preds = predict(SVM_radial, test, type="class")
acc = sum(ifelse(preds == test$HeartDisease, 1, 0))/nrow(test)

table(preds,test$HeartDisease)

overall_SVM <- acc

paste("The overall fraction of correct predictions in the test dataset is :", acc)
```















## Results

- What method would be the best?

```{r}
library(knitr)
df1 = data.frame(Method = c("Logistic Regression","LDA","KNN","LASSO","Bagging","Random Forest","Boosting","SVM"),  MSE = c(overall_logit,overall_LDA,overall_knn_1,overall_lasso,overall_bag,overall_RF,overall_boost,overall_SVM))

kable(df1)

```





